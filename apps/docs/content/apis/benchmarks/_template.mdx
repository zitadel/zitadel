import OutputSource from "./output.json";
import { BenchmarkChart } from '@/components/benchmark_chart';

TODO: describe the outcome of the test?

## Performance test results

| Metric                                | Value |
|-:-------------------------------------|-:-----|
| Baseline                              | none  |
| Purpose                               |       |
| Test start                            | UTC |
| Test duration                         | 30min |
| Executed test                         |       |
| k6 version                            |       |
| VUs                                   |       |
| Client location                       |       |
| Client machine specification          | vCPU: <br/> memory: Gb |
| ZITADEL location                      |       |
| ZITADEL container specification       | vCPU: <br/> Memory: Gb <br/>Container count: |
| ZITADEL Version                       |       |
| ZITADEL Settings                 |       |
| ZITADEL feature flags                 |       |
| Database                              | type: psql<br />version: |
| Database location                     |       |
| Database specification                | vCPU: <br/> memory: Gb |
| ZITADEL metrics during test           |       |
| Observed errors                       |       |
| Top 3 most expensive database queries |       |
| Database metrics during test          |       |
| k6 Iterations per second              |       |
| k6 overview                           |       |
| k6 output                             |       |
| flowchart outcome                     |       |

## Endpoint latencies

<BenchmarkChart testResults={OutputSource} />

## k6 output
```bash
TODO: add summary of k6
```
